{
 "cells": [
  {
   "attachments": {
    "image-2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAACWCAYAAADwvRwgAAAAAXNSR0IArs4c6QAAAERlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAA6ABAAMAAAABAAEAAKACAAQAAAABAAABFaADAAQAAAABAAAAlgAAAAARD26tAAAzrklEQVR4Ae1dB3xUxdaf2U2yCb13LFQVqQmQgA0RFZ9ixS6KhYDtPbGh76nY37M+CxJAnwp2RX1PPxUrKhIQEooEkCZFEUF6STbJ7nz/s7t3c3f3tt1suZvM5Hdz586cOXPuuXvPPXPmzBnOZJIcsDkHxEtDO1RVezoLxg8TzHsYw5kOIUQHxlkXzniriFsQolxwdhBwhzhjhxgTB5lg+1G2FecNODZzLjYyh9iUPe7HNRHtZUHMHAC/ZZIcsA8HxJRejdzORgWC86H4cQ5lgudDcDRKMIUeCJ2V6GOhwOFwiB+zflu4gk9m3gT3WyfRS6FSJx9r+twUaSGVVd4TBRMF0CqOgwDpbwvqoemAnmLQ847L43yHXz9vty3oSgMipFBJg4dUl0gU7/TKcu9pMowJcQbuCwfvZv/7E5XQmD7lnL2eleX6iI+dW2F/mlNHoRQqqeN9velZPFWQU9mQnQtt5CLYMkYwznPS9+Z9tpk3OOfPuQqLf0rf+0gc5VKoJI639R5zxbRBfxHMcTl+ZKOgkTSoawyB/WW+wytecE1Y8Hpdu7fa3I8UKrXhnmwbwQExZWC7SmfGOC9n4/Hjah8BUAcLMAu1E4beKdkNyh/jY5Zjxql+JylU6vfzj9vdV84YnO/1OiYC4ei4IU0zRNBcdjiZuD2rcMGraUZ6XMmVQiWu7Kx/yCqm548UXj4JRswT6t/da98xbEc0LT3Odd3C5doQdbtUCpW6/XwTdnfuaQWjhWD3Ysr12IR1ku6IhShy8apbeWEJnO/qT5JCpf4867jcaVXRkBOqmXgSmkleXBDWfSTrucN7Xn3SWqRQqfs/6rjcITST3jBIPonp4BFxQVjvkHhvyy5c+GR9uG0pVOrDU67FPYpnBzdxu/iDmBK+AWictUAlmzL2uavKcym/8UfMFtXdJIVK3X22tb4zd9Hgy72cP4EFe21rjUwi8HEARtxfOfcOr8uLGKVQkT/2CA5UvJDXUzgzpkGYnBhRKQtqzwEh9jkdfFTmuOJva4/MfhikULHfM0kZReLlk7LdlRX3g4BbMNzJTBkh9aJjUcWFuNQ1fuF7de12pVCpa080xvupKCo4HbFGoJ0wxCqRKWkcEOz27PHFTyStvyR0JIVKEphs5y7EtNxMt8ikWZ2b7ExnXaaNM3Gnq3DBY3XlHqVQqStPMob7EDMGd3J7+McQKH1jaC6bxJEDXHhH15WhkBQqcfxhpBOqiqL8s+ANOwu2k6bpRHedppWLEdnjFnyZ7vcohUq6P8Eo6ReTT8pwt6+Aqs1hjJXJXhwQBzn3DHaNW1RmL7qio0YKlej4ldbQYmpBxwrO3oWLPUI3ymRHDmA91fZswQbwCcW/2ZE+KzQ5rABJmPTnQPm0wcMqHGKpFCj2fpZ4Pm3wnNI66JMUKvb+jcWFOndR/kVcOD7X3MoiLj1IJPHkADkd4pn9I544k4lLDn+Sye0U9FU+Lf9aPOTpsKHIZ50C/sfcpRBeh+AFWROKf4wZR4oaSk0lRYxPRrfl0woewFdvhhQoyeB2nPvg3OHh4j3aBynOmBOOTgqVhLM4NR1gyngKVJN7UtO77DUeHEDE/s6VGU2eiQeuZOKQKnEyuZ2kvsqLCl7FYGdMkrqT3SSSAxgGQWfpk07TzFJTSeQPIgW4pUBJAdMT2SWGQUI4n0tkF/HGLYVKvDmaQnwQKNjkSmooKXwECeqaD6soGnxGgpDHHa0UKnFnaWoQwobyIgTKJanpXfaacA5w/rSYzNLifU0LIhP+wNK8A/e0/L9jxviaNL8NSb4hB3iPinYFYw1BbFIphYpNHkSsZLin5l8mGH8o1vayXfpwACESaLM22ycpVGz/iPQJxDh7hHDw1/QhZE2d4gDnx8BuNtzu9ySFit2fkA595VPzj4BTW50LRahzu7I4wAH4gPzN7syQfip2f0Ia9ImXhjZ2V3sWQ6j00KiWRXWaA1jH7PF0y75+0Qa73qbUVOz6ZAzogkB5WwoUAwbV6SrM8TkzbB36UwqVNPsBIkD1bRAoI9OMbEluHDmAvYPG2Hl6WQqVOD7sRKNyTx1yLOPi4UT3I/HbmwNYJNrC3a7gVLtSKYWKXZ9MGF0U9V5g1Sq0lKywKnlZDznAubjQrrcthYpdn0wYXW6R9QgCVfcMK5aX9ZQD8E061663LoWKXZ+Miq7K6QP7QaDIQNUqnsgsa2bX9UBSqKTBr9Prdb4CMp1pQKokMZkc4PbUVjKSyQPZV/Qc8M32cCY3+4qedfWgBT/Ojjcpnd/s+FQCNME42x5bkq7HYsEcG5MpSUshB1xZ5c352KV7UkhCRNdy+BPBEvsUuFnWZClQ7PM87EiJuypnsN3okkLFbk8kQI94ccjhyMpwBjZ9PnYhiwuRbxdaFDqkUFE4YbOzu1o8AZKkcdZmz8Vu5GAlkBQqdnsodqSnsmhQX0whX2BH2iRN9uKAYGygvShi6RGezm5MSzQ9Xu78e6L7kPjrBgewjUdL8cJxze10N3L4Y6enAVoqXizoxoQ432ZkSXJszIEqZ/WRdiJPChU7PQ3Qwj3ibsz4yOdis+diZ3KwJkwKFTs/oFTSJmYMbos1HWNTSYPsO/04gF2XpVBJv8eWHIorPY6rk9OT7KVOcYCLLna6H6lm2+hpQI29zkbkSFLShgP8MDuRKoWKTZ5GxfT8U2BRsZUaaxPWSDJMOCCEaGYCktRqKVSSym79zuDEdK1+rayRHNDnAKaVG+rXJr9GCpXk8zyiRzGzT0OECDw7okIWSA5Y40Bja2DJgZJCJTl8Nuyl8lAORfHKNgSSlZIDOhxAIOxGOlUpKZZCJSVsD+1UcH5paIm8khywzgHOmBQq1tlV9yHFy/1gZJNbbtT9J53IO7SXTSWpkd9ypy3uiq9yN+ZhrWBcaoGI4C2gurWgLQdgwaazC9Oq+3HeD8PlfsYEDsd24RBlWOK9rqQwb30iH00qcFdVZktbSioYL/tMGAcSKlT6TF3WJtNRdQUX/EQIiwIIi1Ycyyr9yxgpg280/nxnbLzmOwev/VcQLNjqxp/Pm1aCK7YKkMVezj6GoJkDQXPI1zBN/3kFPzNwy2l6B5JsG3CgwgY0BEnwv8nBy/hkoJGcwwS/BnLizPhgNMAi2GfQdj7Ci/kBBMzvBpC2q6Jd5tzt8g/I6G62ezRpRpDYm124wDa+KnETKgOn/NRZZFQWQpMYC6Qdkv1UMFyC8sK+YQ7+hhDe2RAwe5NNQ7T9lRcVDIfg/TLadhJeckDNAXxU/8gpXNBOXZbKfK2HP71eLGuR46l4QLDKG+hG4ialouQKXk6ayRqOsAHDMaR6CdrSh9zrfGbxhP5zo0SVNHDOxIjUcSxpt5nwjpy5V7OM/lcy5qli7pdP8fWXkX8jcx47momDO1jlm+bxrlxXfsZYZg7zlM1m1cXPJpzmeHYA88C+eOKrLa5aTSnnFpWOz/GUrwURPoFSW2Li2R6C5Rzm8H4D4fJ1/6LSgnjijhcuGK2Pjxeu+oyHN2gFO12mTygofFDKuMuiX1gWZmWBg7uaKCiYo0Muc435xHewbNuMLoL0KRmMDrYreTucY9JUBk4payecFW/DgnqC3b+0EC7DnFzMzysq+YwJ592LJ/RbYgfGi2e7udyCDUqZamcHJsSJBrET37VDfzJRHbu9UuzeyHh2E+bFWUm8cXu4JAaESYZLKbbdGaOD9BYqedNLRwlR/jKESQvbcdeIIM5ORwSk03OLFs+syMi5pezaXruMwBNdV5HZqgBDtpiEeqJpSzf8npUfMDpqkyrfu7w2zVPblvMdqSUgtPeoftR4IW+DP8lj+PqnynQSSn0MV/CPGZPtqRg5oKhkYun43NdiQBGXJg4HGwq1td4lR9fhzNkTs+ikBUCzEDvXMc+aT5l3a4kmLxyHDWHOHmcw3rIbvmMOJvZtZZ6lMwFfGoTnrXoyR2dsf1O+h3lW/y9YrpdxdBrshweAd/N85v1tMewvF2L4lM28v3zHxJ6NzDlgLHO07x9EkTlwHBPlu1n1gueDZXbJwKbym11oITqsCRUheO70kikQJhPsRHystEAitoZYnAV7y9Vep2PskmsHbIoVV6ztwNL8+jb0yTr/FQiHHiEso2sHhIZn9Ues+rtHVXWcZZ7yIHN0OVlVBrnSpBNzdBqEl/8bVvWFPz648+izmfPocwAnTIWKo/tpLHPYvYDFr8BTyTyr/EIoo+Bmn9DyNj2MVc19iGVAqDBHzevh6D7SR4cdhQpE44YQJqX4wpKhNnda6X/qikBR85vsLQ6PKMsrKjWfHlA3jEMezoD5cUCTNigyhk6sESgHtjHvmk+Yd/0XjFX5fRedR53FeJtjgveTceJdNQIFLz9pMmJPjex3HDmMObqfHoS3knH0GBkiUCpnX+nTSrTaen9d6LPTKHXizzWYuP1JubTVmTvZOjsRVCOKdajKLSr5N77qV+lUp30xvlcNYXB+F1rL1IrmOX8ru7BXZaJvCnskH+aGd3Gi+4kX/s073exQpZcd1T72LZ2dR57kJ6fyIHO/cV4NaQ4nc439CtumZbGMvpf5tQ8YR2nI40vV5cz92ijG0I4SDZuyLpnty2f0Op9VrsVUsIVEQ66ME+/2Q2LYVfneFRhK6Y8aqj673TdMU9pUfn4nYwf+sNBT8kEyvdW2EiqGmgrc4m+BQPlr8tmU/B5JE8veXTEfwiXhofkqRWZe8u8wuh4rqrxsdslONurZVazn35ew/vcvYwvWYylWrMkZmD3JasB4syNqsHg9GG48zDwr3mWeDV/7yn0+J4ENBaq+fywoUKhS7P+die0rfHC8SUff2eyf86hRKoFSzirfvcxQoJjhs1W9EPt4YcmfdqJJV1OBbwd0UfGUnYhNNC3QWnIxLP8pr2jJBYvH94dunqDEWe8EYa412q9X7WVv/fgnBMqf0E5CTcm3v7uRfT8pNtK9O1bCFgJjKmwZWRe+4RvKeDf/4LOl0DDINxQKUM+bHxm8D++m+cG8kqn8cJySNT9nNWYZJ0wKwpFjGwmmupKwMm6p3e5FU1M5abLIgJ39DbsRmxR6OG8CC94nmDq/OFH9eRk7KlG4Y8G7/NdDbNJ7m9iRd5awvzyzis0q3hEhUAjv4o0H2fZ9VbF0warm3BliE+HNDmfOPpdCwLzJXFd9gRf/LuCFWKf/NDNEyYu+KmuhHfmxhPzPyL8JBti6s0U1vLKXhdygDS40hcq+9qV3YNjT1wb0pYYEzjPg7v8mPIYnJoIADLVsIVTmrNjD+t63lA1+aDl75svf2ba95gJj/roYX3IYWyvfuYRVfXwT826ah60YVUuzshoyMtRmnvG0j93cCe9YSljQFZfk3ufvk5BlNoCx9r64oLUDEmgq9hcqsCm0h/T7ux0YlmoaEO/lSdiVHsOP2/8JjRdBgh0dL1S1wTNh1nq25o8KXRRn92/OHr/w8JD6bftitGOTKz0O8i+pmnMHc88cydyvjGDVi4qgkXh8fTg6+fcaDw5PYLwNai0qKmhNT9aoqRAO96hKdbLQdsgwXPU5hkCBmSZH11NCZpp0WqZFsZN57C9UwMlH8SVtkBYcTQ6Rt9OUery6ElMGdoaWn3Kf7+nf/sF+N9BMju/emL1V2JPdeHJ7dvGglsHb33mgOpi3nGnYmrku/5/vcB6NmRwlYUbHs2QmfEU+DJRAdmPmx4vpWyVFTBtj6EKLBXm7vhAMvRQw/TO57pMwEV6f/4kCmHXa40o2fc9wbc8a/+Niu91AyPBnwIySPhAoV9qNyFTTQ1Pq0Fgmx4OO6syMLvHAUxscldVe9sj//aqLAvfLpl7RNVjfp1PDYN4Ri86GlcLM6xdGGf2vgstl6NS0o10fP36CqdjDqhfPCGovGf0uh7bSwV+f3ZRlkjCgxYNI3l++9Zdb/O/9ZS4TO1b5oXOas4whtxi2FNXuYL0Tiwvtl3ix/WjC41ET5fCywES+ulTmAxy4D8bb82vLjWpP6jfTfvH77ewPA4PrRQNbsq5tsoO32ji7xrDZtIHuhGEQXivj+fljf3GjtjDMfuY30F76AXNdNw9Ocd19dZ61c/ww0CzIFd+XIICyLnmXua7+yrda2NE5319OLvOLpvnzUfyvxNCLtBZKzmMvYLxpZ93WPttPoDbjpH8w17XRCTFdxHGqgPCfGydUcUUTFCr9pi45Anax0XHFXseQCa94HVPttfMx4akXKo9/pu/0RY/szpGdQp7cAbff5kGFTXNqBEwIkMlF9fePM/H7Ej8UhRjA7A+DgKH1PJS8m75n1d8+7K/Hf9JWqn94MiAAoB75tBu/miR2rWPuD64OCgfFJhNsTJmA4Agpo4tDOyGwXgsUYynAaf/y57WMwnC883nWBqAVDUm5TPXZ4fDMTTUNWv37nxJqYKB9BkOfm7WAZJmKA0LsrBIZfZdN6Gf8ZqqaqLPuovyXEUflKnVZMvPvw6Htshlrdbs8sUcT9tlEuCip0t3vb2JPf+737Xjv+p7sL32aq2qjy5Jm4CT3ethZaEhEIQdIIxD7t+ogwq+yfV/f4j4B937x+9Kk+5mQkx3HmiCiUb1UQIfgZBXvzy4shvuD/ZJfl6XZjWmlVwTcBOxHpZ0o4rxlJvO8CpJOiYUsTAG2j6VdvNq88I2x49f4k6A9hKV1qhmibqphURiYpUuxd4vfZmIJmoAQLBGCxIMjVYnc+Y1c+lNCl2CBsWJKejfs1Kd7Dpyx5ASMz2L//Bh2UQcrORuO0AmXx3RnnEW+tTEhir7Rit8OsR/WHdBt2KKhk50zoGamRwH88Rd/G1cGZz3bhRpZFRh5Ti4HHA6vf3l1cru11JtPqCBGygWWoCVQkAMYNz7b/z+l0OGjS4KxNtG1iB/01G+2GSI7T0Og/L6nMmjU7dVRehoYMjBplUJkOjOUefik9Wq1I79QYeJEqw0knJ8DpNk5qrxTouUHhFFgfjTalrWD31vuYf+Zt90QyeiBrSLqP4XXrZIGHFYztayUyXMKOCDYt/yaH/anoGdLXToKntqSgz16elmClkAhHIAJcXTe1KX9QwoNLsTMPil7K99auMOAMqhPjTMZObyFpw9LdwaLTu3VLJiXmRRygLN3Uti7adeOigY7huCr69NYTKElQCQHuOeRyEKdEncOQranJr0631ionDugBYKEBicDfUTur/CwL1buDRI8QgqVIC9SmPG4sireTGH/pl0jVKrX8pfWFFt9BEBA7X7Tlwy0cutu7ohUBaw0rCUMGWiXbD5oiGVk70gt5E2VdnNar6YsO1N+ewyZmJRK8Q0fu7RmTJqUPqPrxIGvU7fomkjocA5keL0PhJdpXTu81SnRVF6e94cWOcGyBlmcnXZs5OTfi9/VtLsgL9LeEkQgM0njAAz9byetsxg7csAL4MgY28pmCgegrfSdvtTcLsUdNb7vStsknF9f8KdhL8OPjtRSSjcdYD/9Vu5rR160F+RFTjUbIpWV8ecAFhBmu4Wt7Sl009BneZf43339wwht5TI73vVnmL2hmR+jNLJ3pJZC8VWUdOXQNnLoozAjtefX+M0L96WWBPPeIVRE5GfKvJ2ECOMAZ15zZzgvdmhJclLP3uh1ffJRod7eP28rZ+8urpn1uenkdnpNZXkSOYCo+f4oVknsM5auEDWSp0Qlj4VYW7fhvHPe1CVDDWlMslCBUyP739JdhiR1ap7FDm8V+hN48H9bgkHXLshtwTq1cBnikJWJ5wDMFAtd1y1Ylfieat9DBranwC8mdCqx9mjrKQaH9xLc+Q+6d+8QCBiSPF4v2HCA7T5kPPQ5+eimIeQu33KQzS6tEUQPnXd4SH1tLt5c+CeWCexja/8ox1ERDBLVu2MOu2hQa3bJ4FasQ7Os2nSh2fb7NfvY16v3soUb9rN12yvYll2V6CeTHQlhOhphHi4Z3Jo1UYV30ELyE2bQJr27EXj8o4/dzw2yNCRcvPEAK5q7DfF9D7BNf7p9ISWuR+Crq48zd6ymPsfPXM92ITDWr7vdvUHXyTj8Ww5oEalfRqORXBwDcPTDQfa/8TgW4DBKZEi7CMeZOAZgUqctPlQk2G7F8SkOzYTVHDxTs0YWRs2BQOiIG3Ubco+XCf8aTl2YOFZ8oHJc00N7fPfQoc/EtzcGQW/EsOfwlrXTUtbjJX7my63sbUTo31fhj2MS7CCQIYPwTx9sZv/A8dJVXdml+VGvfghH6bt+6fs/2LOwDWmFzNy6p4rR8QNi7j76f7+xr27rFRJDRkG4ZZfbR9c7i2qGgyOPbWZJoLyHIeQVL4auCC/bWs5ueG0D69Uhhw3uYuxhcA9Wh5du8rsC4GXeA5qsCpSzATsIBwmQfhAGIV7cwPULyo0ECgmhR3FchbYhaiyuj0b5J8AxEufPcEQkCvC8D15Pob+sCDBZYIUD8B1rg+h5R5del6uppgqRYaw2WOkkCphPlu82hVZrKv9dssv3klEjmvG5+y+hcVVMkakAPF7Bnvhsqy/CXKXHuinpmlfWs4PYuOy6E9qqsEWXpQWQE/CFX/l7uaWGFLBq2OMr2KJ7+rK2Tfzf2D2HqtnDiI73/FfbInD8pW+kYTsc6POyPRECRQ3zJZwKjYTKlyv3sDlle9VN3lRfGOSH4cX/0KCeqmYZ1NMQ/i3gMHv4rwOuIw7E6wxNGP4w0uekUAnlS+xXXp+KqilUEDjIowQlir0Day03QtVev8NtCNy5RVZwuEE7EN4B9V5J/77kSNa8YWxaFRl6r3xpLVu25ZCCznc+E3FYyHOXnOimYkgwb+3+kHrl4uY3fmHDjmrKYgmzQPfwnIYgINzd2rjYHQhAdUpgyPdf2JtueWujr9sd+6t9guiNwh4+7eapz7fqzpqd2beFr43evx37q9gl037Wq/aVk7eyXtoLgXbdq+vDq+kltpJuswCkJ1SuhDB5xUJ78r5uAW3lDMC+Hw6fgfge+5M3yg/vvu5dw/GHxr1TtO4MuylhR3CtmviXfV5mrqUMPKJRsONrX17HNsPWQIle/osHxebsthrawcn46ofbcl65uhvsJjU4z8ttyXKx66GeNvHvL7ay5y+z7u1Aw5SLp60JDheCNxbI/G1Ee/bo+aH2ofEn+We1FMFCiye7Tiphuw7qP6T+WFSpaDPhfSjXFFkvfCM2pU45H2YwrLx0+pqQ7VLw8tJHaonS1uDcCy87vei6CbhKULlOA+BBtP2HRrlRUR4qI4QKTSn7LU9GTWWddQ5wcZIesMsT2BBYDyCO5V9A/TZLeQGhQobEDzD0odSqUQabfmVXs6aa9Rt2VLDTniqLECiETy1QlMZjj9c3VloZuil4lsG4PAh7Fyn2B6VcOU86o2OEQFHqSLDQPSvJSKAQzJkmQx/yCZqBnQrMUp9ODTRBCjFsU4zBKoDXVHmjrL49r6aVlkfu6zEIFMLYsAZtTc7BBTf/pNXAy5wpB3gLhOY8ShMsI/uAZnkCCuf+bP6toDE9zYgoX2oi48WrusU07KG4K6c+Wca2YxihTlcNbc2uKNA2vNLsi16i7UPKsZ+zWSrG/s6nPFHG9ujMclHf943qbIhGrbEZAqLSLJTma9jdsaLa2IaUk8nZcWEGcur33g83s5naCz/fMKMrUH+pBbh3VTCkqn4HgWKlnapZMLs9mFNlHIKLNaprmY0DB4SX99FCk6wYGPPW7mMH3OYvZBsYJc+bsjpI6i2ntscaIDL8R5egUrOLitaw3zCbok40TfvEhUeoi0LytAm8XqKtQHJMFjDS9PfIp1fq3iv54Dxz6ZF6XQTLO8G2ZCXRsKdvZ82Pc7D5FxaGnaccE8njO7Ht7OMwbIcn8HYeyjaGl2tcj4FwaKJRHiwCrmW42BgoIFXpE7Q5nq5Rtx/HszjOwFEz1RUA1jlt1iqnKeWVWhWyLHYOcIc4Fq3f0cFA1knjuUSdhlaLv4Nfhlnq2trFLnhhddB+MPCIhuyRGH1S/v3F72wR/DDC022nd2ANXfrR97fu9ttwwtvRdfe2+loM1W/bW8lGPbeauQ20ghcu72IqmAjXfpNlDARDyWzoQzCrYaQ2S+p1VCu3HmJXYtp5BaaadZJVLWWsTnt1sTqu7f9UAmUTgM7EsSIAXIrziEDe6LRIqzLDI/gqZ/K9x7VoqTtlgpNQ0UxQjHfhI5xQobIAQwKzpJ4Zat04g713vfaIzQxPGRy07oHarpXGmjh4fbcmZMo0BMWlcEgzSuc8vzoY5lIL7izYPqzGf9l5MHTIpoWPys4ymfUhmIMWNETSdj79abdvKQQ5BJqkt0zqqbojBMRJFuAUv5KPAD+c4KGVfI8TCRT1l0j390ttKKEdGeFq1Fxfqf9fRmZ1Tpk3M3TqT1Uvs7FxQPehQH7vwjR+6DREbH3otlICVesChFW8iWlUGgrFkq7C1DFc+iJS7uENYQDVx7kbLzJ5uWqlZg2crPDEtlpVvrK/vflLxHR1OHA0PjY0c2SWyA5iZWjYER7Bf5psDdtvMo1CzBNe3I8AZcXmebE5Nh/EN/g/CwKFhAgJhoU4nY5DLQCOQX17qjdJc/XqHT/eePRO2gRBD0CWR88BOMF1123FLY9XdVEYVayB+m22KlndftqYLmxoN8OhuBo8JE8eu3pqu5bdQN34iTn6065vjOvB9HZCpFXX00xmV07o0Zj1sxhPl/xFVm+rUJOmmT+pZ1PN8vDCc+CHE8c00yKu88zgIEB+AMyTEBiXEyyuyZGGvGLVAoWqzqV/FtL7ejCYUvYlkmAyxZED/V8q7aCFDn5BCRXgC38xH/oodJEb/pghbZTLqM8PfvSrbpt+BgbNj5ftZk8FNicLR/AsDKvk+KaXyHXdLE08lRw9rSW9aejw1qdpRMYLh6HrG4e3hzFXe7o4HJ5c9c/u3zy82HeNl558At7TrAwtbAJBMSS0SPOqG+AmUg1w/4nTGTi0tKCLCMZC+lgPRhEqn+sByPLYOMC9QlOF5EJEmvhj60KzFdk4rKST8eL+64LYR2GkpawycIPX286DlgKMnkofychEWpORe76RZqRgo4WCVoYpCvzcn7WHYEq9ch6pERlPqVOfG8Ew/fmtvdhNw9upi4N5EiTjsAThi1uPYYvv7cuW6of51NUEgsj8mVPCrjUvIVB840kIFLIIn4ZjgwZgHuB6a5SHFAHHHBToMi6DoKu8mZ9mOawZq0Kwywt9DgimKVTg36z/edfHZrlmg4lrPiE6At6cb47vwRw0bxtjensRfez0U0dM56oTLQN4+OMtmhpKD8z0kIOc0VoYwvXPT35To9TMaznZaQIGCt8yN5Sy7tiV0cgDNhw/TaXfelpH9gZw7wzYV/56Snt295mdQlZDP4q1RZt26s6AWdFSqOuTw/s3uT4H9aU6MFfplIcXvxJeoL72CZXlE/puz5u2uAzL8nupK2W+Fhzw6AgVITZBsNQCsXFTWhVslo7DVhxmS/3NcHytirKvBdsgS1GC4VCHWLeP4AUihzZ1auRysElndMILqDlSVIPCW/YAW/6ruRZ2MUIoWE2LsPBw4063Kfgpx+gPx/QakwFbESg922Wzf4ZphWQc/ten2kISmgANSz7Vwx1W7vMzCSvTvATesajQG5WQLLhMs6GqEDgO4tJQi/IJFX8b/gnOUqioGFibLOeilVZ7qJcbhVZFnMrIVd4stTSYlTFrS/XzES5gv8HUaWMIC3Kdfx9DpNfhYRruFJcN7yiyPdwGYaJnkA2nQx2EO7xOuW6OWSM993cFRn2eVbxdfambN7LxaDV6cs5WpvZonjamawTYJDi7GfjYaLnSR+BAAdlT+mhVhJdBGDyHslfCy1XXZwNXpFeeCiCQnYWzrnpFMEGhghmg/8AR7vZAQ3mqJQfwgBppocjKcq11V5p/HbXampWRQ5iZizjhUK91McOpVf/VKrIh6icSOPkP/xQBMKRrY18gJhqiNDYJihTeWP2Shtcp14OO1GS5Uh1y3ldezV4rNh7CKQ2O79FEyZqeSeBSXBgl0bqj8GEdCf73VYGwFFjV2YpvCoFbFSjrAXunCr9WdoxWoUbZqxplIUVBoVJSmLcaa1ZKIVgGhEDIi5g4AM91TX9uPnZuRXlR/jYIHW1LXky9+Rsp6rYZiiaIlVKb9KuBJ2w4XjKcXnN8W3Y5Ai9FY5dQ46Fp318QysEshb+8RvC0w4CVtUWk+TRrEHxNjFD6otmplz2Ql7LWuqNn4IGsl6BR0PTdt3r1YeVWPRZvQzsy0Oql5vg9jtKrVMpBGwmnBcq13jmEWxAoLwNQChU9bkVTzoWmUPGj4GtxjrtQoeBGVlJOVu2ECi0eNEsjYIf424gOTB0EyqyNXr3BDElIk2hi6ZptVq8gJic+KwnhHtmZz6wM+gi1gZfym4U9I5pS8KeZ8w2HXd9FNNIvOEa/yl8TEFIfmsCR8dZKmmkFqMaaBujqLMdrGAaFWtOsYJEwkRzQ0VQIkDOxOrJB7UtIpbeSKCpbrOmVH7YzCsJklsi4GQ+BUg1ab3nrF7PufPVkU7GSKNTDWgsGbcJF8VPM0nZEjst7YHkwHg153/73pqNZ+AwY4ZkBo7XJEHWRWX+B+otwPtEC7HwLMKMtwBAI2VPM0uwQobJ0bP890FZmm7WS9RY4wGvsVRrQCREqNG1rJVlZn6KFhwTKhFkbWJWF8JBfrdJ1Y9BCrVt2CVY/U1xXK6mRBTsNaVn3qGweZni7tc0xBKGh4LDHVgQ1FAKeeW0PXY/eNxbsMMSHSlMAwFyE4QrZXaxMS60x6bAhcJFnrWGCxkPCyUy6Pwpc54UIFcJaxZ0PGWKXlZY4AOGsbwTgQlkNagmXVaBMp7Wp6i27KqyiDMJNh2s8CRRKDVXTxUGAsAxt7E6G41jTzgNV7HSENfjYF2fXmmZltOpZoePG1zfohkpQYNTnFgYhNSky/9BHlrMNKnvPc/AI1lvNTM6CFpYEmDFtfECgEJlWLMhmQmWg+n4N8h8Z1FHVzaBrEoSPiBAqy8b1K4ORUdcF1wSxrA5wALzVFSouVr0wEYyyalBcutnc30NN312zN7G/YhGfkprkhJjilOKQM35D7L7/bgkps3pB4QAGPricfRsMNGVNWK5AO6NEU72f/OSfuRrarTE7p38LI3BfnV4s2U3wb6HgUOqgVDTTc61BwO7ZJX9akY6HGRD1CF7cqar6bFVeL7tOryJQblWoGBmPJ4KuZwgfzjxCqPg64uK+QIfyFCMHwFtddYAXluyF7erXGFHrNmvfNNSLVQ/wW8RboeDMZolWEp/1zCpG8VKURGESCvBCWkkUxewjk83MwvGQk9vJj5eFOMpZNZZSGEcKGq2VaCGiMtXbEuEjX8eiRaf2rz+kuZbDHbn2D0b4SorCrySKkaI106PU03n24p1L1dc6+ct0yv+L39RdSh0+WjRLZEVImUn2XAWnyXmtTj0JuieVOtD1qSZbMb1cisovFEB5jp4D+FIbGgIQAmFJ9FiNWxzRyuXbWsMYyl9769sbDcFo86sBDyxjX6psI+ROX3x3H3Z2P/MvvIL8QthEaLsKs0Qawf3YGXHoo6H2idF4WWcgxKWVRNHuKM5KuGAhTetclCuJVkFTFDcrw8XH4PVKkfQo0ZQ90Tjy6VUhNpSb4YI/69ruCnrtsxAvYPhTI4W0oehL3wVVZC85KXBcgPNKlAenfPFu7kLZCTg031+Uq5O2224NRPuarGEu/KG3BvSnYYLue5Sdr6vHCie/l3stRX8ypKT+VvoevO7tw+N2PlYsn6ULEGMFOZhRVHizRHslkxB64JxQbZtivtIGXB8GAmEreAq6NmIf3HCUzwOWZjXIgc4sbojS9mxEaJtwUltf8OtwXxKKkfs6jJcU27W8KvTDew0CYysR9ZtkO3Q3I1P6oTPtythu4mLfSuFyGK7DNxKj8JYnBJzZWjfOVDfVzJM2MuLJlb7tPdZtjxzR3jGyA7v/7FAehiOCVvpt9rYFN6HcTGvwNcWLehEydEQkCJRtKDwFRxmOUIZFQPsKzH4MrbSbRZRORMn4QCkJuJdAZ7At6PoGZWfiKNcVKtgQawGc4V6FwfHKACJ5ioYD3NiKj0/MPE80+CzCXjGktSWhQugoJirtokfTvyQgyBtUrdIrXV6W38oXEFu5pvPEUzuwu9/frC4yzE+d+wf2+vnDB3N4yyyfQ1n4vkBqBJMRrPpO2CiURLsWFgXaK2VGZy3cFAT7BtVm852au4xQhNRpCRQyyhrZUHwIhNiYnek8i09mXlzX6pHjxSXnsxNxKNqH9ljP17Hlf2aGYR8iCJBC9H86Lpoi30yNHeUzcD1OKTNTn26DKDSTdAoueVZxQAjuf4NUZepsZuHCeerreOXPHdCStW9q/gVW+iNP1RnfbWcfwG1cS6D88/zDIgQKtR0/jLZEtWbDUfpSzrQyV+ulp3paF/Sfsd1CBAqVXz/MqpZO0JGJ9mkO33pkYBRu/WqMtHvjnInHmAsU37sjTlUFPLcuhdUdIo8Xl34vg3EoAoUgDtI/vYQ2Vt7dX/Xah5dDmByuIVBuA1xQoFAbQ6EC2woWR4jbw5HLa3MOYHhj6DbpwyDYHHNM0UNYiSBvhvXo9jms5N4+7K/witVKFOmePEbjueCaghuV3tfXtz4ovE8KhH39sLbhxZauyYhKgio8FWCoSKEro0kUof+Hu3oHh1AGbSscwjMie/zCtSqYr1R5y1kIh/sBfDyOnWGNyFhrlKxoMnONEBjVga7zUB800iqwhkKFgCBYXsRpvtJAnq1xoMqRqf6iaDfivmA32nW1KKUAzVebBJ02Qv/QuYf5Xu5jOjQwAvN5m2qtwDVspFHpgnZCfS74ex92ZOtsDQh/0WTYLmgXgGjSab2aGhpRrxraxjI6WstTfHdvzY3cw5B4sMXtqKzxPy4OK38eL6KZIAg2AexqHKSdTA4WhmbMNBEacpmlF6OhiZABvhhHD2Q/0EJuKlSoERzixgJTuRYCWabFAVGx/Lq+5mqlp5rCTSQkTcH2FKP6NY8K98WDWrKfH+5vKb6JgpjsFB/dfBSz6iKvtFPO1Oey+/tZ6pNWNn8I93erfV13QhsfvNKX1nnSyI6M1umYpQfP6cy+m9SbtbJg3EXUvyuhoXyhgZO8ZS/RKA8pwgt7AMckFB6N48eQytAL3WXWaL8CoC+HgmtekevznZo1YYXA+TuO61A8BIdaAwuBtOZVhCZ5RaUXMC7eDWktLzQ5ADvU8pLC3L6alWGFFdPyN8Bl6Miw4rhd0qzKAx9tYVsC+ySHI6ZZFQpFcNPwDqZ77YS3VV8fcHtY0Tfb2PNfb9O0zahhO2LlMvV59XFtrXz11U19+a1wtb9+1no2p0x7KQDNgN0BYWE1rCStZboae0mHx6ttkMWxp3RrdtdfOjEa9lhMN2UXFj9vAktDmQ9hnwiZpsULS5rHCziexqErMFCnpFeA40q6QFtyqPwOB03rzsOxG0c06XoAk89J0/BGwL0OZeTc9hIOU+XCslChjnKLSqZgDE2dy2TAATyE90rG5402AAlWQag8BaFyS7AgQRnyUl2JNTTkCXqo0sNcGQ5GNoVoYoVYJY02MyPfjvCFi51buFg+tlo9CvaaeCRaxzMfU+AU7c5d7fVt13pG7+asi8EQyqjfEvjmLIbzHS0QJFovHNiKqSPYGbVFnQcv0xhXYfEbJnDq6mG4GISDGFKK4384oknUnlIxDl1nSx+EtX+NADYWR8sA+AGcv8SxNHBt6QQ+RJfyikoWYZltXnSt6h30/YsLcydbueuqqflDPQ5OXxaZ0pcDFfAYOTd7fPFn6XsL8aPckk1F3V2lM+NcKFvk0SeTDge8nIUb6HQgGcucsOAHaDaWnKJ0kciKlHEAjm27sI5zuBQoNY8gaqFCBkiPcJwMwWLZil3TXf3IYRuOBVHdKWczo4KXwLbgAJZiLM52iL6Z44rl7KjqiUQtVKjtkvEDllVzJ7zrRDzGcSpy0j8LI+1Wv3+P9XvJznTDCCYseTZaxyohE8kBPOdZ2bxyCL9uofksXyIJsSHumIQK3cfScf2xdoWdDbOzFQcbG956YkiCkeq7aDHzq5fswJj81WjbSfjUcEB4xbicwuIxWG1elRoK7N1rzEKFbgtf5M+xI9XFUAOtONnYmxNxog7RDz+PBRVmYx6GgJZ8jIV5SWsjfuFe3jtnwoIZSesyDTuqlVCh+108bsBszhxw15VDIeKHyOIf0znaxK+dv0lw35L3aJtK+GRwQIj3XRnOvq4J81cko7t07iPqKWW9m+03fclAp/B8glXNrfRg6no5ZgJKob3lxnqfYlruYW6WCUcjbn1FYKydyXaWOEDBtByC3eYav+BtSw0kkPGCwmj4AxvLIq/TkYeHsD6adnUJFgK1Vj88jNE3c8Efqks8Sed7wW/54WxW1VMKlOieYtw0FaXbXi+WtciprngHDnLDlbL6cq50ZHS2tObHhCHlRQWL4LksHQxN+JSwasHew14Id2VfW0zu6TJFyYG4CxWl/7xpJTfC8PgY1sbHxydbQWzTM4zVH5SMz6Wl4LVO4j/9W7srsxdAMHepNTKJwCIH8ATxDLEn0z2u8QtXWmwkwTQ4UGtDrQZOXxHc1J+vZk5aVLdID6ZOlXNxd7zuh6aYXbxyMPDFNJMULzrqDR7sHuHgngHZ4xecLwVK7Z96wjQVNWm5RaV3Mu69CzaHiBWQarh0zeMTNxUG2oQstHQXFdyFWaFH0pU3tqZbsP86HNWTs8YtimrBnK3vyQbEJUWo0H32mbmsYeYhz40QLrfVpRkiKM3LKjzZx5Xd0OtAop5nxfRBPZjX8QyGkhQjVKZacADPazuGOG9z4Zgup4drwUiDpkkTKgoNR7z8S3ZL986r0fGteEnS2maAH+jriDEzDlrKIeX+EnmueGFgF+HIuBa8u0jaW6LjNLRJCBL2OoY4H0XXUkJHy4GkCxU1gYjWfxwTfAxekNEgpJm6zub51zyCP4o1UCkz6FXOGJzv9fJr4NNyOXilH4PR5oxMLHniG6wAn5XtOfAuv6EsYZpkYu8h/bCnVKio2ZVXtORswTznQXsZZUsBg3CasG284M1wPLXkmgFb1bSnMi+eHdykysXP9TA2EnSMwNAyJJpYKmlLSd9CUEyTT1yZztmIYm+b55QSXqSoU9sIFfX99y8qPcHBxFmISI8XhfdS1yUvj2UHgs+FFjUPIfbmLRo34Nvk9R17T9Bgcr1ehKYQ5CckTqj7U/qCIqbNw/1+6TrEv+QTi03DHcbOXdnSCgdsKVTUhPeZuqxNFvfCU9dDzmAD4BQGN3jeSQ0Tn7z4A0JkAwkRDG3mYGjzVXzwphZL5fQhA71e7/F40L29jGNPDdEzfbUZxEoV7Cf8BpbBRlLsqj4wXw5rUvv70urd9kJFi+iCp7bklDf4s5PD6W3nELwjnOzaY+xMaj+mrHlj/Oga40fXGD9AKBl8H8rp2EsHNvnah5v25b1OXwS7313722wsnti53nzhxPODWmLI1B386e7xsm7Y/qk7tJquEKjd7CBwKCYNntEKxrzLhJevdHLvCo3tLvA4ZbIjB9JSqNiRkXWFpoCNphuEdBeanUMshgbqe8MMCoQ2b4b65hDg5HeEM2squGimJ5AgJHZgGtcnyKENImK88Al2yPy9GOLu9nohRJx8M/Kbs/bzjXIIo+Z4+uX/H+t0u7uPCQi7AAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "id": "ff8ee9a1",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "## The Scikit Learn module\n",
    "\n",
    "The [scikit learn](https://scikit-learn.org/stable/) module is an open source module dedicated to implementing machine learning methods in python. It is the tool we will use for the next few weeks to explore these methods and apply them to some data.\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "- There are particular sections of the module dedicated to supervised and unsupervised machine learning tasks (recall these are where we have training examples and where we do not respectively). \n",
    "\n",
    "- Here we are going to focus on supervised classification methods (KNNs and Decision Tree example), that is, given training data classified into two classes (denoted 1 and 0), we want to use that data to construct a way to classify new data points based on that information.\n",
    "\n",
    "Firstly we are going to need to import some modules and functions to get started (we'll particularly take sub-modules connected to nearest neighbours and decision trees):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeeb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pandas library for data manipulation and analysis\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the entire scikit-learn library,\n",
    "import sklearn as skl\n",
    "\n",
    "# Importing matplotlib.pyplot for plotting and visualizing data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing seaborn, a data visualization library built on top of matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "# Importing neighbors module from scikit-learn, which includes algorithms for classification and regression \n",
    "import sklearn.neighbors as nei\n",
    "\n",
    "# Importing the tree module from scikit-learn, which provides decision tree algorithms \n",
    "import sklearn.tree as tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6c61a",
   "metadata": {},
   "source": [
    "For the given examples below, it is better to check out these functions in detail during your study\n",
    "\n",
    "- **KNN model fit :** [KNeighborsClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "\n",
    "- **Data Splitting:** [train_test_split](https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "- **Decision Tree model fit:** [DecisionTreeClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bf3bfa",
   "metadata": {},
   "source": [
    "## Reproducibility of the results\n",
    "\n",
    "To make sure that we will get the same output if we run the same function several times, we provide the pseudorandom number generator with a fixed seed using the `random_state` parameter. \n",
    "\n",
    "This will make the outcome deterministic, so this line will always have the same outcome. \n",
    "\n",
    "- To control this, we should be careful about the use of `train_test_split` and `DecisionTreeClassifier` function input arguments for this week material\n",
    "\n",
    "- We can set that value in advance in this format given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a88cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the fixed seed\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92db59",
   "metadata": {},
   "source": [
    "## First example: Simulated Data\n",
    "\n",
    "The first example we will work with is a synthetic dataset, made as it just has two features, which means we can plot the data points within the feature space more easily to get a handle on what's going on.\n",
    "\n",
    "Our dataset comes split in two parts `synth.tr.csv` and `synth.te.csv`, the first one containing our training data and the second our test data. Both therefore have labels, but recall we don't use the labels in the test set to build our model, just to compare with the predictions of our classifier to see how well we do.\n",
    "\n",
    "First let's load in the training dataset and have a look at it. Here is a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbdf089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data from a CSV file into a pandas DataFrame\n",
    "class_data = pd.read_csv('synth.tr.csv')\n",
    "\n",
    "# Display the first five rows of the dataset to understand its structure\n",
    "print(class_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d312ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of 'xs' vs 'ys' from the training data, colored by 'yc' class labels\n",
    "sns.scatterplot(data=class_data, x='xs', y='ys', hue='yc')\n",
    "\n",
    "# Add a title to the plot and show the plot\n",
    "plt.title('Scatter plot - coloured by class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3be9bb",
   "metadata": {},
   "source": [
    "## Fitting KNN\n",
    "\n",
    "Next we want to make a [K nearest neighbour classifier](https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) based on this training data. To do that we start a classifier model, specifying K and the distance metric we will use (here we specify `K=3`, and normal `Euclidean` distance).\n",
    "\n",
    "We can predict a value of the class label for a made up data point - here we try the point (0,1) which looks like it should definitely be a 1 since it is in the middle of lots of orange points in the plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a k-nearest neighbors classifier with k=3 neighbors and Euclidean distance metric\n",
    "knn_class = nei.KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "\n",
    "# Fit the KNN classifier on the training data ('xs' and 'ys' as input, 'yc' as target labels)\n",
    "knn_class.fit(class_data[['xs', 'ys']], class_data['yc'])\n",
    "\n",
    "# Use the trained classifier to predict the class for a new data point [0, 1]\n",
    "print(knn_class.predict([[0, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5191a4ce",
   "metadata": {},
   "source": [
    "**Don't worry about the warning we get from the last line - this is just saying we passed in data without heading names within a dataframe - and the training data was in a dataframe - so just warning us of the mismatch.**\n",
    "\n",
    "Note that we have two methods associated with our classifier (denoted by the . notation to get to them). \n",
    "\n",
    "- One is the `fit()` method that we pass in our data to. The pattern is the data points - here simply two columns of our dataframe, and then the associated label, here contained in another column of our dataframe. \n",
    "\n",
    "- The second method `predict()` is used to apply our classifier to a new data point - we can give it a data point and ask what class the classifier gives as an output.\n",
    "\n",
    "- As you explored above, the default settings of the parameters in `KNeighborsClassifier()` function is crucial, since by default it runs k=5 case as `n_neighbors=5` and `metric='minkowski'`. Make sure that you did the correct changes\n",
    "\n",
    "So far so good then. We have a classifier, and we can test it out on a data point and it gives a classification. The next step is to look at our test data and see if we can begin to qunatify how well our classifier has done.\n",
    "\n",
    "First we can load in and have a look at the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ca10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data from a CSV file into a pandas DataFrame\n",
    "test_data = pd.read_csv('synth.te.csv')\n",
    "\n",
    "# Create a scatter plot of 'xs' vs 'ys' from the test data, using green color for all points\n",
    "sns.scatterplot(data=test_data, x=\"xs\", y=\"ys\", color='green')\n",
    "\n",
    "# Add a title to the plot and show the plot\n",
    "plt.title(\"Scatter plot of test data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e2c7d",
   "metadata": {},
   "source": [
    "These are all of the data points in the test dataset. We then have to classify them by using our classifier above. It will find the nearest three points in our training dataset to each point here, and let them vote on the class for the point. With 3 neighbours selected there cannot be a draw.\n",
    "\n",
    "We can use the `predict()` method again here, this time passing in all of the data points within our test dataset. The next line creates a new column of the dataframe which we call 'class'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e88da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained KNN classifier to predict the class labels for the test data\n",
    "test_data['class'] = knn_class.predict(test_data[['xs', 'ys']])\n",
    "\n",
    "# Print the test data with predicted class labels\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d5ba9",
   "metadata": {},
   "source": [
    "We can look at the results of this classification. Here is the test dataset coloured according to the predicted class of each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of 'xs' vs 'ys' from the test data, colored by predicted class\n",
    "sns.scatterplot(data=test_data, x=\"xs\", y=\"ys\", hue='class')\n",
    "\n",
    "# Add a title to the plot and show the plot\n",
    "plt.title(\"Scatter plot - test data coloured by class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1712c",
   "metadata": {},
   "source": [
    "We could also overlay on the plot all of the training data. Here we do that using triangular markers for the training data.\n",
    "\n",
    "You can look to see the closest 3 triangles to each circle - they are the ones which voted on that classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of 'xs' vs 'ys' from original data, colored by predicted class\n",
    "sns.scatterplot(data=class_data, x=\"xs\", y=\"ys\", hue=\"yc\", marker='^',legend=None)\n",
    "\n",
    "# Create a scatter plot of 'xs' vs 'ys' from test data, colored by predicted class\n",
    "sns.scatterplot(data=test_data, x=\"xs\", y=\"ys\",hue='class')\n",
    "\n",
    "# Add a title to the plot and show the plot\n",
    "plt.title(\"Scatter plot - test data coloured by class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7804e8",
   "metadata": {},
   "source": [
    "## Assessing the classifier\n",
    "\n",
    "Looking at our test dataset we have two columns now which contain the real class of our data points 'yc', and the predicted class 'class'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the first five observations from test data with real vs predicted classes\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99199ff8",
   "metadata": {},
   "source": [
    "Note that we can't see much from just the top of the dataframe. But if we look through the dataframe we can find locations where the values in these two columns don't match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsetting the cases where the true and predicted values do not match\n",
    "print(test_data[test_data['yc']!=test_data['class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205182a",
   "metadata": {},
   "source": [
    "- Note we have made both types of errors here (FP and FN cases), places where we have predicted a 1 but the real answer was a 0 - a False Positive. And also places where we precited a 0 but the real answer was 1 a False Negative.\n",
    "\n",
    "We can summarise all of the True/False Positive/Negatives in a confusion matrix. We can also look at the balanced accuracy and F scores (look back at the slides to see the definitions of each of these). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e10370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and display the confusion matrix comparing true labels with predicted labels\n",
    "print(skl.metrics.confusion_matrix(y_true = test_data['yc'], y_pred = test_data['class']))\n",
    "\n",
    "# Compute and display the balanced accuracy score for the model's predictions\n",
    "print(skl.metrics.balanced_accuracy_score(y_true = test_data['yc'], y_pred = test_data['class']))\n",
    "\n",
    "# Compute and display the F1 score for the model's predictions\n",
    "print(skl.metrics.f1_score(y_true = test_data['yc'], y_pred = test_data['class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02359f",
   "metadata": {},
   "source": [
    "We can see we do a pretty good job, the majority of points are well classified. \n",
    "\n",
    "Let's compare to another model to see if we can do better - let's try KNN for the case K=5. Here we fit that model, predict the classes on the test dataset and compute our scores again just as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a k-nearest neighbors classifier with k=5 neighbors and Euclidean distance metric\n",
    "# and fit for the data again, then make predictions\n",
    "knn_class = nei.KNeighborsClassifier(n_neighbors = 5, metric = 'euclidean')\n",
    "knn_class.fit(class_data[['xs','ys']],class_data['yc'])\n",
    "test_data['class'] = knn_class.predict(test_data[['xs','ys']])\n",
    "\n",
    "# Compute and display the confusion matrix comparing true labels with predicted labels\n",
    "print(skl.metrics.confusion_matrix(y_true = test_data['yc'],y_pred = test_data['class']))\n",
    "# Compute and display the balanced accuracy score for the model's predictions\n",
    "print(skl.metrics.balanced_accuracy_score(y_true = test_data['yc'], y_pred = test_data['class']))\n",
    "# Compute and display the F1 score for the model's predictions\n",
    "print(skl.metrics.f1_score(y_true = test_data['yc'],y_pred = test_data['class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55f22c",
   "metadata": {},
   "source": [
    "### Classification Metric summary\n",
    "\n",
    "It is possible to get a classification metrics summary by using the function called [`classification_report`](https://scikit-learn.org/1.5/modules/generated/sklearn.metrics.classification_report.html), as exemplified below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6baa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a text report showing the main classification metrics.\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate and display a detailed classification report\n",
    "print(classification_report(test_data['yc'], test_data['class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a360a1f1",
   "metadata": {},
   "source": [
    "So by all of these metrics the K=5 classifier appears to be a bit better than the K=3. \n",
    "\n",
    "## Second example: Diabetes Data Set\n",
    "\n",
    "\n",
    "This second data, namely `pima-indians-diabetes.csv` contains measurements of various health indicators for use as a predictor for whether the study participants would go on to develop diabetes. The final column gives the true outcome for what happened to each participant.\n",
    "\n",
    "We can load in the data. Note there are more columns in this data - so the feature space is now 8-dimensional, which means we cannot simply visualise it all now. We will just look at a cross-section of the feature space and show the sixth column against the second column to get a small sense of how the feature space looks.\n",
    "\n",
    "Data Source: [Smith, J. W., Everhart, J. E., Dickson, W. C., Knowler, W. C. and Johannes, R. S. (1988) Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications in Medical Care (Washington, 1988), ed. R. A. Greenes, pp. 261–265. Los Alamitos, CA: IEEE Computer Society Press.](https://pmc.ncbi.nlm.nih.gov/articles/PMC2245318/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ced4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading data set via pandas\n",
    "diabetes_data = pd.read_csv('pima-indians-diabetes.csv')\n",
    "# Looking at the first five observations by using head\n",
    "print(diabetes_data.head())\n",
    "\n",
    "# Below returns a view object, that contains the keys of the dictionary, as a list.\n",
    "print(diabetes_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08158ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the relationship between glu and bmi based on class split\n",
    "sns.scatterplot(data=diabetes_data, x='glu', y='bmi', hue='class')\n",
    "plt.title(\"Scatter plot - coloured by class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d454ed",
   "metadata": {},
   "source": [
    "- We can see some separation of the different classes, but of course we are missing the other directions in the feature space in our plot, so we can't tell whether those which merge together in the middle in our plot might separate out more if we look at other planes of the data.\n",
    "\n",
    "- In this data set all of the labelled data is clumped in together in one file. **So we need to split it ourselves into a training set and a test set.** We can use a function called [`sklearn.model_selection.train_test_split`](https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.train_test_split.html) in scikit learn to do this for us. \n",
    "\n",
    "Note the form of the following line. \n",
    "\n",
    "  >- The function outputs data points for the train and test portions, and separately the classes for the train and test data points - usually called X and y respectively. \n",
    "  >- In the input of the function we need to give the columns of data which make up our feature space, and the column with our labels. We also need to specify what fraction of the data we want to be used as a test set (usually we want to retain most of the data to do training with). \n",
    "  >- Here we specify a third of the data to be our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c57922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data set into train and test subset \n",
    "X = diabetes_data[['npreg', 'glu', 'bp', 'skin', 'ins', 'bmi', 'ped', 'age']]\n",
    "\n",
    "y = diabetes_data['class']\n",
    "# Considered split ratio is the 70/30 for the train/test subsetting\n",
    "X_train, X_test, y_train, y_test = skl.model_selection.train_test_split(X, y, test_size=0.30, \n",
    "                                                                        random_state = random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98363244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape (dimension) of the original data, training and testing datasets\n",
    "print(diabetes_data.shape)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27898297",
   "metadata": {},
   "source": [
    "Next we can use the `fit()` method to fit our KNN classifier for K=3. Then use the `predict()` method on our test data to obtain predicted classes for each data point in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a k-nearest neighbors classifier with k=3 neighbors and Euclidean distance metric\n",
    "knn_class = nei.KNeighborsClassifier(n_neighbors = 3, metric='euclidean')\n",
    "\n",
    "# Fit the KNN classifier on the training data\n",
    "knn_class.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained classifier to predict the class for a new data point\n",
    "y_predict = knn_class.predict(X_test)\n",
    "\n",
    "print(y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3db06",
   "metadata": {},
   "source": [
    "Now we have both the real classes (contained in `y_test`) and the predicted classes (contained in `y_predict`) we can use these to obtain our various metrics to determine how well our classifier performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b08e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the Confusion matrix\n",
    "print('Confusion matrix: ',skl.metrics.confusion_matrix(y_test,y_predict))\n",
    "\n",
    "# Calculating the Precision value\n",
    "print('Precision: ',skl.metrics.precision_score(y_test,y_predict))\n",
    "\n",
    "# Calculating the Recall value\n",
    "print('Recall: ',skl.metrics.recall_score(y_test,y_predict))\n",
    "\n",
    "# Calculating the Balanced accuracy\n",
    "print('Balanced accuracy: ',skl.metrics.balanced_accuracy_score(y_test,y_predict))\n",
    "\n",
    "# Calculating the F1 score\n",
    "print('F1 score: ',skl.metrics.f1_score(y_true=y_test,y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c06f63",
   "metadata": {},
   "source": [
    "We can also look at the difference between the true and predicted classes in our slice of the feature space. Here is what they look like - you can see at least a few points which are different across the two plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b17a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X_test, x='glu', y='bmi', hue=y_test)\n",
    "plt.title(\"Scatter plot - coloured by class - true class\")\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(data=X_test, x='glu', y='bmi', hue=y_predict)\n",
    "plt.title(\"Scatter plot - coloured by class - predicted class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6d25b",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "We can also fit a decision tree classifier to the same data, via [DecisionTreeClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.tree.DecisionTreeClassifier.html). \n",
    "\n",
    "- The nice thing about the scikit learn module is that the `fit()` and `predict()` methods work in a reasonably standard way so fitting a new classifier model is pretty straightforward and follows a similar pattern.\n",
    "\n",
    "- To do it we make a new decision tree classifier, use the `fit()` method with our training data, and use the `predict()` method with our test data - all in pretty similar fashion to the way we did this for the KNN case above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57125d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Decision Tree Classifier object\n",
    "# To get the same result for each run, we fixed the random seed here, otherwise without \n",
    "# using `random_state=random_state` you can get different outputs\n",
    "dt_class = tree.DecisionTreeClassifier(random_state=random_state)\n",
    "\n",
    "# Train (fit) the Decision Tree classifier on the training data (X_train, y_train)\n",
    "dt_fit = dt_class.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained Decision Tree classifier to predict the labels for the test data (X_test)\n",
    "y_predict = dt_class.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the trained Decision Tree\n",
    "tree.plot_tree(dt_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea30730",
   "metadata": {},
   "source": [
    "As you explore above, some of the parameters of the DecisionTreeClassifier is really crucial to work out including the `max_depth`: The maximum depth of the tree, as an example \n",
    "\n",
    "If we use the default as `None`, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples. As we can see from, there is a large complex tree appeared and not easy to navigate. \n",
    "\n",
    "To simplify a bit, let us set the `max_depth = 2` to see how the fit looks like if we consider such a pre-determined model parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28961d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Decision Tree Classifier object\n",
    "dt_class = tree.DecisionTreeClassifier(max_depth = 2, random_state = random_state)\n",
    "\n",
    "# Train (fit) the Decision Tree classifier on the training data (X_train, y_train)\n",
    "dt_fit = dt_class.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained Decision Tree classifier to predict the labels for the test data (X_test)\n",
    "y_predict = dt_class.predict(X_test)\n",
    "\n",
    "# Visualize the trained Decision Tree\n",
    "tree.plot_tree(dt_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf5262f",
   "metadata": {},
   "source": [
    "Now we can see more readable tree fit output, but remember that we manually set the parameter as 2. \n",
    "\n",
    "- Considering the order of the variables in our data set from `X = diabetes_data[['npreg', 'glu', 'bp', 'skin', 'ins', 'bmi', 'ped', 'age']]`, looks like in the root node, the variable `glu` is selected to start with the splitting, thereafter `bmi` and `age` are used in the internal nodes. \n",
    "\n",
    "- In terms of the split, we can see which proportions of the data is splitted as diabetes or non-diabetes, which are captures in the `value` (such as 349 vs 188, their sum should match with the `samples` value) parameter for the each node based on the model fit. \n",
    "\n",
    "- This structure is preserved for the all nodes from root node to the leafs (from top to the bottom)\n",
    "\n",
    "- In terms of the flow of the decision tree, when the `glu <=154.5` is **TRUE**, we followed the left branch and considered the `age` parameter for another split whereas if the condition `glu <=154.5` is not true (**FALSE**), tree splitting follows the right-hand-side branch and the model used `bmi` for further split. \n",
    "\n",
    "- In each node, we have also unique indicator called `Gini impurity` that we did not discuss in detail so far. For the scope of our course, no need to worry about its technical details but feel free to explore from that reading blog;\n",
    "\n",
    "[A Simple Explanation of Gini Impurity](https://victorzhou.com/blog/gini-impurity/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b6616",
   "metadata": {},
   "source": [
    "Now we have the true and predicted classes again, we can go ahead and find all of the metrics which detail how well the classifier has worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the Confusion matrix\n",
    "print('Confusion matrix: ',skl.metrics.confusion_matrix(y_test,y_predict))\n",
    "\n",
    "# Calculating the Precision value\n",
    "print('Precision: ',skl.metrics.precision_score(y_test,y_predict))\n",
    "\n",
    "# Calculating the Recall value\n",
    "print('Recall: ',skl.metrics.recall_score(y_test,y_predict))\n",
    "\n",
    "# Calculating the Balanced accuracy value\n",
    "print('Balanced accuracy: ',skl.metrics.balanced_accuracy_score(y_test,y_predict))\n",
    "\n",
    "# Calculating the F1 score value\n",
    "print('F1 score: ',skl.metrics.f1_score(y_true = y_test, y_pred = y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfad442",
   "metadata": {},
   "source": [
    "Comparing to the KNN classifier above it looks like this does generally worse.\n",
    "\n",
    "**Self-Thinking**: How do you compare both results regarding each performance metrics one by one ?\n",
    "Focus more on FP/FN values or certain metrics we obtained above.\n",
    "\n",
    "Once again we can plot our cross section of the data showing the real and predited classes - again we can see some differences as we would expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49738065",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X_test, x='glu', y='bmi', hue=y_test)\n",
    "plt.title(\"Scatter plot - coloured by class - true class\")\n",
    "plt.show()\n",
    "\n",
    "sns.scatterplot(data=X_test, x='glu', y='bmi', hue=y_predict)\n",
    "plt.title(\"Scatter plot - coloured by class - predicted class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2011a10f",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Here is a new dataset that contains 4 columns in the relevant dataframe. \n",
    "**The first 3 columns represent the features, the fourth is the real class of each data point.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data = pd.read_csv('haberman.csv')\n",
    "\n",
    "print(operation_data.head())\n",
    "print(operation_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd91f8",
   "metadata": {},
   "source": [
    "1) Split the data up into a training and test dataset, use 50% of the data in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1481d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17ba2db7",
   "metadata": {},
   "source": [
    "2) Fit a decision tree classifier to the data and output the balanced accuracy and F1 score.\n",
    "\n",
    "Hint: Consider fixing the `random_state` parameter inside of the `DecisionTreeClassifier()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94ce25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a45ac622",
   "metadata": {},
   "source": [
    "3) Fit the KNN classifier with K=3 to the data and output the balanced accuracy and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d5911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7c6bef2",
   "metadata": {},
   "source": [
    "4) Which method did best? What's your justification for that conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccbb642",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
